%
% File naacl2019.tex
%
%% Based on the style files for ACL 2018 and NAACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage[utf8]{inputenc}

\usepackage{multirow}
\usepackage{xspace}
\usepackage{url}
\usepackage{tabularx}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xstring}
\usepackage{scalefnt}
\usepackage{bm}
\usepackage{paralist}
%\usepackage{microtype} % microtype breaks non-ascii use in bib
\usepackage{tablefootnote}
\usepackage{subfig}
\usepackage{capt-of}
\usepackage{latexsym}
\usepackage{paralist}
\usepackage{calc}
\usepackage{booktabs}
\usepackage{url}
\usepackage{scrextend}

\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\newcommand{\aspectbox}[1]{{\setlength{\fboxsep}{1pt}\colorbox{lightgreen}{#1}}}
\newcommand{\posbox}[1]{{\setlength{\fboxsep}{1pt}\colorbox{lightblue}{#1}}}
\newcommand{\negbox}[1]{{\setlength{\fboxsep}{1pt}\colorbox{lightred}{#1}}}

\definecolor{lightgreen}{RGB}{200,255,200}
\definecolor{lightblue}{RGB}{200,200,255}
\definecolor{lightred}{RGB}{255,200,200}
\definecolor{lighterred}{RGB}{255,220,220}

\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\mt}{\textsc{Mt}\xspace}
\newcommand{\blse}{\textsc{Blse}\xspace}
\newcommand{\barista}{\textsc{Barista}\xspace}
\newcommand{\vecmap}{\textsc{VecMap}\xspace}
\newcommand{\muse}{\textsc{Muse}\xspace}

\newcommand{\rt}[1]{\rotatebox{90}{#1}}
\newcommand{\rrt}[1]{\rotatebox{45}{#1}}

\newcommand{\ie}{\textit{i.\,e.}\xspace}
\newcommand{\eg}{\textit{e.\,g.}\xspace}
\newcommand{\F}{$\text{F}_1$\xspace}


%jer: automatically turned off when aclfinalcopy is turned on
\usepackage{annotates}
\newcommand{\todo}[1]{\comment{Todo}{#1}}
\newcommand{\jer}[1]{\comment{Jeremy}{#1}}
\newcommand{\toni}[1]{\comment{Toni}{#1}}
\newcommand{\alex}[1]{\comment{Alex}{#1}}

\newcommand{\jeranswer}[1]{\answer{Jeremy}{#1}}
\newcommand{\alexanswer}[1]{\answer{Alex}{#1}}
\newcommand{\tonianswer}[1]{\answer{Toni}{#1}}

\newcommand{\jerin}[1]{\inline{Jeremy}{#1}}
\newcommand{\toniin}[1]{\inline{Toni}{#1}}
\newcommand{\alexin}[1]{\inline{Àlex}{#1}}



\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{On the Effect of Word Order on Cross-lingual Sentiment Analysis}

\author {\textbf{Àlex R. Atrio$^1$}, \textbf{Toni Badia$^{1}$}, \textbf{Jeremy Barnes$^{2}$}\\[5pt]
$^1$Universitat Pompeu Fabra\\
{\tt toni.badia@upf.edu} \\[1pt]
{\tt alexratrio@gmail.com} \\[5pt]
$^2$University of Oslo\\
{\tt jeremycb@ifi.uio.no}
}

%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\}

\date{}
\begin{document}
\maketitle
\begin{abstract}
Current state-of-the-art models for sentiment analysis
either explicitly or implicitly make use of word order.
This is problem for cross-lingual models that
use bilingual embeddings as features, as the difference
in word order between source and target languages are
not clearly resolved. In this work, we explore reordering
as a preprocessing step for sentence-level cross-lingual sentiment
classification with two language combinations
(English-Spanish, English-Catalan). We find that reordering
 helps both BiLSTMs and CNNs, and that a simple reordering
approch outperforms a more complex MT-inspired reordering
scheme.


\end{abstract}


\section{Introduction}



%When facing a relatively simple text such as an hotel review, we can ask for its general sentiment. Is it positive, or negative? Is it better to ask for more gray areas in between? Automatizing the process of classifying the sentiment of a text is called Sentiment Analysis (SA), and it can allow us to get a good understanding of how the author(s) of these texts feel about the topics that are discussed in them. Of course, there are issues that we may find in this process. For instance, given a certain text, its sentiment may be ambiguous: two independent human annotators may disagree in it. Or maybe the text does not have an overall sentiment, and we should focus on individual sentences.

Cross-lingual Sentiment Analysis (CLSA) exploits resources, \eg labeled data of a high-resource language, to train a sentiment classifier in order for it to classify low-resource languages. This is relevant when a target language lacks plentiful labeled data, particularly when considering specific domains. 

Machine Translation (MT) is often used to bridge the gap between languages \cite{Banea2008,Balahur2014d}, but requires parallel annotated data, which may be difficult to find for some low-resource languages. Approaches that use bilingual distributional representations, in contrast, have been shown to be competitive while requiring less parallel data \cite{Chen2016,Barnes2018b}. All things equal, these approaches, therefore, are preferable.

Recently, sentiment classifiers pre-trained on a language modeling task have lead to state-of-the-art results \cite{Peters2018,Howard2018,Devlin2018}. This suggests that sentiment analysis benefits from learning word order and fine-grained relationships between tokens, which can be gleaned from unlabeled data. Current approaches, however, have only been applied in a monolingual setting. 

In this work, we perform an analysis of the effect of word order on cross-lingual sentiment classifiers that use bilingual embeddings as features. We show that these models benefit from reordering the target-language test data so that it resembles the source-langauge word order.


\section{Related Work}

\subsection{Cross-lingual Sentiment Analysis}

Although most approaches to cross-lingual sentiment analysis rely on machine translation \cite{Banea2008,Balahur2014d,Klinger2015},
there are several approaches that instead rely on bilingual representations. 
\newcite{Prettenhofer2011b} adopt Structural Correspondence Learning to the
bilingual setting. They create useful bilingual features by predicting the existence
of ``pivots'', which are words that are both predictive for the task in both source and target languages.

Bilingual word embeddings \cite{Kocisky2014,Chandar2014,Luong2015} now provide
a simple framework for cross-lingual approaches to natural language processing. 
Current state-of-the-art approaches \cite{Artetxe2017,Artetxe2018,Lample2017} first separately create monolingual embeddings using large, unlabeled corpora in the source and target languages. They then learn an orthogonal projection from the source to the target space in a supervised manner using a bilingual lexicon. The orthogonality constrain maintains the relations that exist between the words before projection.

Bilingual word embeddings are now used as features for state-of-the-art document-level \cite{Chen2016}, sentence-level \cite{Barnes2018b}, and targeted \cite{Hangya2018} cross-lingual sentiment analysis approaches.


\subsection{Word Order in Sentiment}

Pre-training sentiment classifiers with a language-modeling task has
become a successful way to do transfer learning. \newcite{Peters2018} learn
to create contextualized embeddings by training a character-level convolutional
network to predict the next word in a a sequence. Similarly, \newcite{Howard2018} introduce techniques that improve the fine-tuning of the base language-model. Finally, 
\newcite{Devlin2018} introduce a self-attention network, and adjust the language
modeling task to more of a cloze task, where they predict missing words in a sentence, rather than the next word given a sequence. They then fine-tune their models on downstream tasks. All of these techniques have led to state-of-the-art results on sentiment tasks.

Because of some problems we may find in MT, sometimes it is considered best to preprocess the source language by reordering it and then carrying out the translation \cite{Bisazza2016}. Transformation (reordering) rules can be determined manually or with data-driven approaches. Their application can be deterministic or non-deterministic. Some hybrid techniques exist as well, where long-range transformations are deterministic and the rest non-deterministic.

\alex{the different claims of the previous paragraph are all from bisazza 16, is this well referenced (reference just once, at the beginning), or should it be different?}


\section{Methodology}

\subsection{Corpora and Datasets}

\begin{table}[tb]
\centering%\small
\begin{tabular}{lrrrr}
\toprule
    & & \multicolumn{1}{c}{EN} & \multicolumn{1}{c}{ES} & \multicolumn{1}{c}{CA} \\
\cmidrule(rl){2-2}\cmidrule(l){3-3}\cmidrule(l){4-4}\cmidrule(l){5-5}
 \multirow{2}{*}{\rt{Binary}}
 &$+$   & 1258 & 1216 & 682     \\
 &$-$   & 473 & 256 & 467   \\
\cmidrule(rl){2-2}\cmidrule(l){3-3}\cmidrule(l){4-4}\cmidrule(l){5-5}
 \multirow{4}{*}{\rt{4-class}}
 &$++$   & 379 & 370  & 256  \\
 &$+$    & 879 & 846  & 426   \\
 &$-$    & 399 & 218  & 409    \\
 &$--$   &  74 & 38   & 58     \\
 \cmidrule(rl){2-2}\cmidrule(l){3-3}\cmidrule(l){4-4}\cmidrule(l){5-5}
 &\textit{Total}     & 1731  & 1472     & 1149       \\
\bottomrule
\end{tabular}
\caption{Statistics for the OpeNER English (EN) and Spanish (ES) 
as well as the MultiBooked Catalan (CA) datasets.}
\label{datasetstats}
\end{table}

At document-level, bag-of-words models are often expressive enough to give good results without relying on word order. Given that we are interested in word-order effects in cross-lingual sentiment analysis, we therefore require datasets that are annotated at a fine-grained level, \ie sentence- or aspect-level.

For this reason, we use the English and Spanish OpeNER corpora of hotel reviews \cite{Agerri2013} as well as the Catalan MultiBooked Dataset \cite{Barnes2018a}. The corpora are annotated for Part-of-Speech tags and sentiment with 4 classes. We use the English subset for training our classifiers and the Spanish and Catalan for testing the effects of word order on the target languages. Although these datasets are relatively small, they are all annotated similarly and
are in domain, which avoids problems with mapping labels or domain shifts.

\subsection{Bilingual Word Embeddings}

Using two bilingual lexicons we jointly project respective pairs of word embeddings in English-Spanish and English-Catalan. We create the monolingual vectors on each language and select the embedding pairs that best transfer the semantic and sentiment content on each of our language pairs. With this we are able to transfer some of the knowledge we have of our high-resource source language to our low-resource target
language. We use a GoogleNews vector for the English, and for Spanish and
Catalan we use skip-gram embeddings using Word2Vec with 300 dimensions based on
Wikipedia corpora \cite{Barnes2018b}.



\subsection{Experimental Setup}

\begin{table*}[]
\centering\small
\newcommand{\lex}[1]{{\setlength{\fboxsep}{1pt}\colorbox{lightred}{\textbf{#1}}}}
\newcommand{\nonlex}[1]{{\setlength{\fboxsep}{1pt}\colorbox{lighterred}{\textit{#1}}}}
\begin{tabular}{ll}
\toprule
\emph{Original} & Único punto \lex{negativo} el \lex{ruido} que las ventanas de madera tan típicas de la zona \nonlex{no} \nonlex{consiguen} \lex{aislar} \\[3pt]
\emph{Reordered} & Único \lex{negativo} punto el \lex{ruido} que las ventanas de tan típicas madera de la \nonlex{no} zona \nonlex{consiguen} \lex{aislar} \\[3pt]
\emph{Noun-adj.} & Único \lex{negativo} punto el \lex{ruido} que las ventanas de madera tan típicas de la zona \nonlex{no} \nonlex{consiguen} \lex{aislar} \\[3pt]
\emph{Random} & aislar madera \nonlex{consiguen} típicas de el de zona las ventanas punto \lex{negativo} Único la \nonlex{no} \lex{ruido} tan que\\[3pt]
\emph{Only-lex.} & UNK \lex{negativo} UNK UNK \lex{ruido} UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \lex{aislar}\\[3pt]
\emph{No-lex.} & Único punto UNK el UNK que las ventanas de madera tan típicas de la zona \nonlex{no} \nonlex{consiguen} UNK \\[3pt]
\cmidrule(lr){0-1}
\emph{Trans.} & The only \lex{negative} point the \lex{noise} that the typical wooden windows in the area \nonlex{don't manage} to \lex{block} \\[3pt]
\bottomrule
\end{tabular}
\caption{An example of a negative sentence (original) with the five reordering
transformations applied. The \lex{bold tokens} are words found in the sentiment lexicon, and the \nonlex{italic words} are words that convey sentiment in this instance, but are not in the lexicon.}
\label{example}

\end{table*}

In order to test whether a sentiment classifier trained on bilingual embeddings is sensitive to word order, we test our trained classifiers on six versions of the test
data, which we describe in the following. An example of these six versions is shown in Table \ref{example}. 
\alex{comment difference between cross-lingual and monolingual test sets.}

\paragraph{No Reordering: }The model is tested on the original data with no changes in word order.

\paragraph{MT-style pre-reordering: }A competing hypothesis is that a full pre-reordering of the target-side sequences will be more familiar to the sentiment classifier trained on English and therefore lead to better results. We implement a version of linguistically motivated rewrite rules \cite{Crego2006,Crego2006b}, which are then applied to the target-language test data.

\paragraph{Noun-adjective Switch: }Given that adjectives are important for sentiment analysis, we hypothesize that adjusting the order of nouns and adjectives should be beneficial if the classifier is learning source-language word order. Therefore, we implement a simple reordering where Spanish and Catalan adjectives are placed in front of the noun they modify, rather than following it.

\paragraph{Random Reordering: }We randomly permutate the order of the target-language sentences. If the sentiment classification models take the target language word order into consideration, this should lead to poor results.

\paragraph{Only-lexicon and no-lexicon: }Finally, we provide two baselines for clarification. The \emph{only-Lexicon} experiment removes all words which do
not appear in the Hu \& Liu sentiment lexicon \cite{HuandLiu2004}. If our systems
take word order into account, they should be affected negatively by this, as the
resulting sentence does not resemble the normal word order. If, however, the models
are simply relying on keywords, this will have little effect.

For the \emph{no-lexicon} experiment, we remove all of the words
in a phrase which are found in the sentiment lexicon. If the models are simply attending to
sentiment keywords, this approach should lead to the worst performance. 

We perform additional experiments with English in a monolingual setup and using a MT-based approach. For the English monolingual setup and MT-based setups, we only test the random reordering, only-lexicon, and no-lexicon approaches.

\subsection{Models}

In order to test our hypothesis, we compare three different classifiers: a Support Vector Machine (SVM) with Bag-of-Embeddings, a Convolutional Neural Network (CNN), and a Bidirectional Long Short Term Memory Network (BiLSTM). Each of these classifiers theoretically have an increasing reliance on word order. The SVM does not take into account word order at all and is therefore our order-agnostic baseline. An SVM can be considered a strong baseline for SA \cite{Kiritchenko2014c}. The CNN considers only local word order, and in this respect is basically a parameterized n-gram model \cite{Santos2014,Severyn2015,Barnes2017}. Finally, the BiLSTM considers both short-term and long-term word order in both directions. An LSTM is a type of Recurrent Neural Network that takes in particular consideration sequential information. LSTMs currently produce state-of-the-art results in SA \cite{Tai2015a,Barnes2017,Howard2018}. 

We implement a single-layered BiLSTM classifier with a 100-dimensional hidden layer, which passes the concatentation of the two final hidden states to a softmax layer for classification. The CNN has convolutional filters $\in \{3,4,5\}$ and a max-pooling layer of length $2$. For both models, we train for 100 epochs with a batch size of 32 using Adam as an optimizer. We choose the parameter for training epochs on the source-language development set and test this model on the target-language data. Finally, we implement a baseline bag-of-embeddings SVM, which is implemented in sklearn, while both neural models are implemented in Keras.

\section{Results}



\begin{table*}[]
\newcommand{\sep}{\cmidrule(r){4-6}\cmidrule(r){7-9}}
\newcommand{\sepp}{\cmidrule(r){4-4}\cmidrule(r){5-5}\cmidrule(r){6-6}\cmidrule(r){7-7}\cmidrule(r){8-8}\cmidrule(r){9-9}}

\definecolor{green}{RGB}{150,255,150}
\definecolor{blue}{RGB}{150,150,255}

\newcommand{\bestproj}[1]{{\setlength{\fboxsep}{0pt}\colorbox{lightblue}{\textbf{#1}}}}
\newcommand{\bestmono}[1]{{\setlength{\fboxsep}{0pt}\colorbox{lightgreen}{\textbf{#1}}}}
\newcommand{\bestmt}[1]{{\setlength{\fboxsep}{0pt}\colorbox{pink}{\textbf{#1}}}}

\setlength\tabcolsep{10pt}
\renewcommand*{\arraystretch}{0.8}
\centering\small
\begin{tabular}{lllcccccccccccc}
\toprule
&& & \multicolumn{3}{c}{Binary} & \multicolumn{3}{c}{4-class} \\
\sep
\multirow{14}{*}{\rt{Bilingual Word Embeddings}} 
	& \multirow{6}{*}{\rt{EN-ES}}
	    && BiLSTM & CNN & SVM & BiLSTM & CNN & SVM \\
	    \cmidrule(r){4-4}\cmidrule(r){5-5}\cmidrule(r){6-6}\cmidrule(r){7-7}\cmidrule(r){8-8}\cmidrule(r){9-9}
		&& Original 	 & 61.6 & 59.8 & 66.6 & 35.9 & 36.3 & 34.9 \\ 
		&& Reordered  & \bestproj{61.9} & 59.9 & 66.6 & 35.7 & \bestproj{36.5} & 34.9 \\ 
		&& N-ADJ  & 61.6 & \bestproj{60.2} & 66.6 & \bestproj{36.3} & \bestproj{36.5} & 34.9 \\ 
		&& Random  & 60.4 & 58.2 & 66.6 & 34.2 & 35.3 & 34.9 \\ 
		&& Only Lexicon  & 59.1 & 26.2 & 53.0 & 29.8 & 16.4 & 30.7 \\ 
		&& No Lexicon  & 57.9 & 55.7 & 63.4 & 33.1 & 33.7 & 33.3 \\ 
	\sepp
	& \multirow{6}{*}{\rt{EN-CA}}
  		& Original & 68.2 & 65.7 & 68.2 & 31.9 & \bestproj{39.3} & 33.2 \\ 
		&& Reordered  & 68.4 & 65.5 & 68.2 & \bestproj{32.3} & 38.1 & 33.2 \\ 
		&& N-ADJ &  \bestproj{68.5} & \bestproj{65.8} & 68.2 & 31.8 & 38.9 & 33.2 \\ 
		&& Random & 66.9 & 64.4 & 68.2 & 31.7 & 36.4 & 33.2 \\ 
		&& Only Lexicon  & 55.1 & 41.3 & 39.1 & 30.3 & 27.4 & 23.8 \\ 
		&& No Lexicon & 64.8 & 63.0 & 63.1 & 30.4 & 35.9 & 31.2 \\ 


\\
\hline \\

\multirow{4}{*}{\rt{Mono}}
	& \multirow{4}{*}{\rt{EN}}
  		& Original & \bestmono{82.6} & \bestmono{76.3} & 70.8 & \bestmono{50.2} & \bestmono{48.9} & 44.9 \\ 
		&& Random & 78.2 & 75.0 & 70.8 & 45.7 & 44.5 & 44.9 \\ 
		&& Only Lexicon  & 63.2 & 60.7 & 49.1 & 37.0 & 33.1 & 38.9 \\ 
		&& No Lexicon & 73.5 & 70.5 & 65.8 & 46.5 & 45.0 & 43.5 \\ 

\\
\hline \\

\multirow{8}{*}{\rt{Machine Translation}}
	& \multirow{4}{*}{\rt{EN (ES)}}
  		& Original & \bestmt{71.3} & \bestmt{67.1} & 69.6 & \bestmt{48.1} & \bestmt{42.9} & 45.1 \\ 
		&& Random & 71.0 & 65.9 & 69.6 & 48.0 & 41.7 & 45.1 \\ 
		&& Only Lexicon  & 61.8 & 47.3 & 54.5 & 32.2 & 27.3 & 35.7 \\ 
		&& No Lexicon & 63.2 & 59.1 & 65.4 & 42.9 & 37.9 & 42.0 \\ 
	\sepp
	& \multirow{4}{*}{\rt{EN (CA)}}
  		& Original & 75.2 & 74.2 & 70.9 & \bestmt{48.7} & \bestmt{42.1} & 44.7 \\ 
		&& Random & \bestmt{76.1} & \bestmt{75.7} & 74.7 & 46.3 & 41.6 & 45.5 \\ 
		&& Only Lexicon  & 52.1 & 59.6 & 43.9 & 26.1 & 30.1 & 32.7 \\ 
		&& No Lexicon & 73.0 & 71.5 & 70.8 & 46.7 & 43.1 & 44.4 \\ 
		
\\

\bottomrule
\end{tabular}
\caption{Macro \F results for all corpora and techniques. We denote
  the best performing embedding-based
  method per column with a \bestproj{blue box}, the best monolingual method
  with a \bestmono{green box}, and the best MT method with a \bestmt{pink box}. We do not denote bag-of-words SVM results, as they are invariant to word order.}
\label{results:all}
\end{table*}

\jer{Alex, can you check the results of the Catalan MT experiment and the Spanish only lexicon CNN experiments. There seems to be some mistake in these experiments, as they don't coincide with the rest.}

In Table \ref{results:all} we report the results of all experiments. Although it is not comparable because they are tested on different datasets, the English monolingual models generally perform better than the cross-lingual versions (13.9 -- 9.4 percentage points on binary and 12.3 -- 13.2 on 4-class). The machine translation approaches fall in between these two.

Regarding the models, there are different trends across the setups. On the monolingual and machine translations setups, the BiLSTM is the strongest model, followed by the CNN and SVM (SVM and CNN, respectively for machine translation). With bilingual embeddings, however, the SVM outperforms both the BiLSTM and CNN on the binary setup, while the CNN is strongest on the multiclass. This shows that BiLSTM displays a different behaviour with bilingual embeddings.

For the bilingual embedding methods, the reordering approach improves the BiLSTM results on three of four experiments (two of for for CNN), while having no effect on the SVM. The simpler noun-adjective flip performs even better, with an average of 1.1 percentage points improvement over the original ordering across BiLSTM and CNN experiments\footnote{We do not consider SVM experiments to calculate improvments as they are invariant to word order.}. This confirms that some kind of reordering is benefitial when using neural networks with bilingual embeddings as features.

The random reordering baseline has a larger negative effect on monolingual models (a average decrease of 4.5 ppt for BiLSTM and 2.9 for CNN) than bilingual embedding models or MT-based models (1.1/1.7 and 0.5/0.3, respectively). Additionally, random reordering has a larger effect on the BiLSTM than on CNN or SVM, which confirms that even cross-lingually the BiLSTM is more sensitive to word order effects.

Finally, the no-lexicon and only-lexicon baselines perform poorly. In fact, only-lexicon is the worst performing model, which demonstrates that all models are doing more than simply attending to keywords.



\section{Analysis}

\alex{Things from the table of results that should (I think) be discussed: even with the "new" way to do the lexicon experimenting, bilstm behaves very differently than the other two, mainly in Only Lexicon}
\jeranswer{It doesn't seem so different to me. Especially if we look at the only-lexicon CNN and see if there's a mistake there.}

\alex{Difference between only lexicon and no lexicon in bilstm still does not seem as significant as it should be (right?)}
\jeranswer{This is probably because there are a lot of words that clearly carry sentiment but are not found in the sentiment lexicon (see the updated Example \ref{example}).}


\alex{why does catalan behave almost invariable better than spanish, even in MT versions?}
\jeranswer{The datasets are quite different, and for Catalan it is easier to get higher scores.}

\alex{why does the cnn not take into account word order at all but reacts so badly in Only Lexicon? What is making this drop?}
\jeranswer{The CNN does take local word order into account. It likely performs worse on only-lexicon because it sees none of the same examples at test time. The BiLSTM seems slightly more robust, but performance is still poor.}


\section{Conclusion and Future Work}

In this work, we have shown that neural networks that rely on bilingual embeddings as features
are sensitive to word order and benefit from reordering the target language test data. 

Given that state-of-the-art monolingual models explicitly learn word order on language modelling pretraining, it is important to realize that cross-lingual models based on bilingual word embeddings are not currently able to do so. In the future, it may be useful to integrate a reordering component into the classification models, which could be learned in a multi-task setup, if parallel corpora is available.


\bibliography{lit}
\bibliographystyle{acl_natbib}



\end{document}
